{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamr\\AppData\\Local\\Temp\\ipykernel_34740\\3778030204.py:152: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_final_df = pd.concat(standardized_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial merged rows: 39644\n",
      "Discarded due to missing DOI: 21667\n",
      "Removed duplicates by DOI: 923\n",
      "Final row count: 17054\n",
      "Saved: Final_ResearchOutputs_Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#_________________________IMPORT_________________________\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "#_________________________SPECIAL EXTRACTION_________________________\n",
    "\n",
    "# Function to extract authors from a string using regex for group 2\n",
    "def extract_authors_with_regex(author_str):\n",
    "    if isinstance(author_str, str):\n",
    "        matches = re.findall(r\"'([^']+)'\", author_str)\n",
    "        return \"; \".join(matches) if matches else None\n",
    "    return None\n",
    "\n",
    "# Function to extract the first researcher from a string for group 6\n",
    "def get_first_researcher(researchers_str):\n",
    "    if isinstance(researchers_str, str):\n",
    "        return researchers_str.split(\";\")[0].strip()\n",
    "    return None\n",
    "\n",
    "#_________________________MAPPING FORMAT_________________________\n",
    "\n",
    "# File paths and group mapping\n",
    "file_map = {\n",
    "    \"group1.csv\": {\n",
    "        \"ProjectTitle\": \"title\",\n",
    "        \"ProjectRDC\": \"Agency\",\n",
    "        \"OutputTitle\": \"title\",\n",
    "        \"Abstract\": \"abstract\",\n",
    "        \"ProjectPI\": \"project_pi\",\n",
    "        \"OutputYear\": \"year\",\n",
    "        \"DOI\": \"doi\"\n",
    "    },\n",
    "    \"group2.csv\": {\n",
    "        \"ProjectTitle\": \"title\",\n",
    "        \"OutputTitle\": \"title\",\n",
    "        \"Abstract\": \"abstract\",\n",
    "        \"ProjectPI\": \"researcher\",\n",
    "        \"Authors\": \"authors\",\n",
    "        \"ProjectRDC\": \"location\",\n",
    "        \"OutputYear\": \"year\",\n",
    "        \"DOI\": \"doi\"\n",
    "    },\n",
    "    \"group3.csv\": {\n",
    "        \"ProjectTitle\": \"Title\",\n",
    "        \"OutputTitle\": \"Title\",\n",
    "        \"Abstract\": \"Abstract\",\n",
    "        \"ProjectPI\": \"PI\",\n",
    "        \"Authors\": \"author\",\n",
    "        \"OutputYear\": \"publication_year\",\n",
    "        \"ProjectRDC\": \"RDC\",\n",
    "        \"DOI\": \"doi\"\n",
    "    },\n",
    "    \"group4.csv\": {\n",
    "        \"OutputTitle\": \"title\",\n",
    "        \"Abstract\": \"abstract\",\n",
    "        \"ProjectPI\": \"researcher\",\n",
    "        \"OutputYear\": \"year\",\n",
    "    },\n",
    "    \"group5.csv\": {\n",
    "        \"ProjectTitle\": \"title_clean\",\n",
    "        \"OutputTitle\": \"title\",\n",
    "        \"ProjectPI\": \"pi\",\n",
    "        \"OutputYear\": \"year\",\n",
    "        \"DOI\": \"doi\"\n",
    "    },\n",
    "    \"group6.csv\": {\n",
    "        \"ProjectTitle\": \"Title\",\n",
    "        \"OutputTitle\": \"Title\",\n",
    "        \"Abstract\": \"Abstract\",\n",
    "        \"Authors\": \"Researchers\",\n",
    "        \"OutputYear\": \"Year\",\n",
    "        \"OutputBiblio\": \"Keywords\",\n",
    "        \"DOI\": \"DOI\",\n",
    "        \"ProjectRDC\": \"RDC\",\n",
    "    },\n",
    "    \"group7.csv\": {\n",
    "        \"OutputTitle\": \"title\",\n",
    "        \"Abstract\": \"abstract\",\n",
    "    },\n",
    "    \"group8.csv\": {\n",
    "        \"ProjID\": \"ProjectID\",\n",
    "        \"ProjectTitle\": \"ProjectTitle\",\n",
    "        \"ProjectRDC\": \"ProjectRDC\",\n",
    "        \"ProjectPI\": \"ProjectPI\",\n",
    "        \"OutputTitle\": \"OutputTitle\",\n",
    "        \"OutputBiblio\": \"OutputBiblio\",\n",
    "        \"OutputYear\": \"OutputYear\",\n",
    "        \"DOI\": \"DOI\",\n",
    "        \"Abstract\": \"Abstract\",\n",
    "        \"Authors\": \"Authors\"\n",
    "    }\n",
    "}\n",
    "# Final desired columns\n",
    "final_columns = [\n",
    "    \"ProjID\", \"ProjectTitle\", \"ProjectRDC\", \"ProjectPI\", \"Authors\",\n",
    "    \"OutputTitle\", \"OutputBiblio\", \"OutputYear\", \"DOI\", \"Abstract\", \"source_file\"\n",
    "]\n",
    "\n",
    "#_________________________MAIN EXECUTION FUNCTION_________________________\n",
    "\n",
    "def main():\n",
    "    # Directory where files are stored\n",
    "    data_dir = \"./\"\n",
    "\n",
    "    # List to hold standardized DataFrames\n",
    "    standardized_dfs = []\n",
    "#_________________________MAPPING & MERGING_________________________\n",
    "\n",
    "# Load, rename, and align each file \n",
    "    for file, mapping in file_map.items():\n",
    "        path = os.path.join(data_dir, file)\n",
    "        try:\n",
    "            df = pd.read_excel(path) if file.endswith(\".xlsx\") else pd.read_csv(path)\n",
    "\n",
    "            # Normalize all column names for safer matching\n",
    "            df.columns = [col.strip().lower() for col in df.columns]\n",
    "            normalized_mapping = {k: v.lower().strip() for k, v in mapping.items()}\n",
    "\n",
    "            df_renamed = pd.DataFrame()\n",
    "\n",
    "            for final_col in final_columns:\n",
    "                src_col = normalized_mapping.get(final_col)\n",
    "                if src_col and src_col in df.columns:\n",
    "                    df_renamed[final_col] = df[src_col]\n",
    "                else:\n",
    "                    df_renamed[final_col] = None\n",
    "\n",
    "            # Apply author regex parsing for Group 2\n",
    "            if file == \"group2.csv\" and \"Authors\" in df_renamed.columns:\n",
    "                df_renamed[\"Authors\"] = df_renamed[\"Authors\"].apply(extract_authors_with_regex)\n",
    "\n",
    "            # Apply PI extraction for Group 6\n",
    "            if file == \"group6.csv\" and \"researchers\" in df.columns:\n",
    "                df_renamed[\"ProjectPI\"] = df[\"researchers\"].apply(get_first_researcher)\n",
    "\n",
    "            df_renamed[\"source_file\"] = file\n",
    "            standardized_dfs.append(df_renamed)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Missing file: {file} â€” skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "\n",
    "    # Filter out empty or all-NA DataFrames\n",
    "    standardized_dfs = [\n",
    "        df for df in standardized_dfs\n",
    "        if not df.empty and df.dropna(how=\"all\").shape[0] > 0\n",
    "    ]\n",
    "    # Combine all\n",
    "    combined_final_df = pd.concat(standardized_dfs, ignore_index=True)\n",
    "\n",
    "    #  Number of rows after merging\n",
    "    before_doi = len(combined_final_df)\n",
    "    print(f\"Initial merged rows: {before_doi}\")\n",
    "#_________________________DISCARDING_________________________\n",
    "\n",
    "    # Drop rows missing DOI\n",
    "    combined_final_df.columns = [col.strip().lower() for col in combined_final_df.columns]\n",
    "    if 'doi' in combined_final_df.columns:\n",
    "        combined_final_df = combined_final_df[\n",
    "            ~combined_final_df['doi'].isna() & (combined_final_df['doi'].str.strip() != \"\")\n",
    "        ]\n",
    "    else:\n",
    "        print(\"Warning: 'DOI' column not found. No filtering applied.\")\n",
    "\n",
    "    # Number of rows after discarding missing DOIs\n",
    "    after_doi = len(combined_final_df)\n",
    "    print(f\"Discarded due to missing DOI: {before_doi - after_doi}\")\n",
    "#_________________________DEDUPLICATION_________________________\n",
    "\n",
    "    # Drop duplicate DOIs, keeping the first occurrence\n",
    "    combined_final_df['doi'] = combined_final_df['doi'].str.lower().str.strip()\n",
    "    combined_final_df = combined_final_df.drop_duplicates(subset='doi', keep='first')\n",
    "\n",
    "    # Number of rows after dropping duplicates\n",
    "    after_dedup = len(combined_final_df)\n",
    "    print(f\"Removed duplicates by DOI: {after_doi - after_dedup}\")\n",
    "    print(f\"Final row count: {after_dedup}\")\n",
    "#_________________________SAVE TO CSV_________________________\n",
    "    # Save \n",
    "    combined_final_df.to_csv(\"Final_ResearchOutputs_Cleaned.csv\", index=False)\n",
    "    print(\"Saved: Final_ResearchOutputs_Cleaned.csv\")\n",
    "\n",
    "#_________________________RUN MAIN_________________________\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
